{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c3ce28-123b-4f34-9751-bd0820ea9f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:58.949156Z",
     "iopub.status.busy": "2022-09-27T12:28:58.948169Z",
     "iopub.status.idle": "2022-09-27T12:28:58.953043Z",
     "shell.execute_reply": "2022-09-27T12:28:58.952279Z",
     "shell.execute_reply.started": "2022-09-27T12:28:58.949122Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4452ee0b-8cd7-4c6b-a456-049347e01aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:58.958147Z",
     "iopub.status.busy": "2022-09-27T12:28:58.954586Z",
     "iopub.status.idle": "2022-09-27T12:28:58.970022Z",
     "shell.execute_reply": "2022-09-27T12:28:58.969207Z",
     "shell.execute_reply.started": "2022-09-27T12:28:58.958109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "X = torch.arange(0,1,0.02).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a0a124-df9e-43e9-9910-a1ed682e2035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:58.973574Z",
     "iopub.status.busy": "2022-09-27T12:28:58.972441Z",
     "iopub.status.idle": "2022-09-27T12:28:58.985962Z",
     "shell.execute_reply": "2022-09-27T12:28:58.985388Z",
     "shell.execute_reply.started": "2022-09-27T12:28:58.973546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff0b039-4f14-444a-ab14-001f95e1cef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:58.988316Z",
     "iopub.status.busy": "2022-09-27T12:28:58.987130Z",
     "iopub.status.idle": "2022-09-27T12:28:58.996742Z",
     "shell.execute_reply": "2022-09-27T12:28:58.995670Z",
     "shell.execute_reply.started": "2022-09-27T12:28:58.988292Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training Data\")\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing Data\")\n",
    "    \n",
    "    if predictions is not None:\n",
    "         plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "    \n",
    "    plt.legend(prop={\"size\":14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbf75c3d-7e6a-4256-abb7-0caa1da484e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:59.002010Z",
     "iopub.status.busy": "2022-09-27T12:28:58.999983Z",
     "iopub.status.idle": "2022-09-27T12:28:59.309813Z",
     "shell.execute_reply": "2022-09-27T12:28:59.309182Z",
     "shell.execute_reply.started": "2022-09-27T12:28:59.001983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4bbe58c-5082-47a1-9fff-b1adbec4eaa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:59.312239Z",
     "iopub.status.busy": "2022-09-27T12:28:59.311836Z",
     "iopub.status.idle": "2022-09-27T12:28:59.319716Z",
     "shell.execute_reply": "2022-09-27T12:28:59.319012Z",
     "shell.execute_reply.started": "2022-09-27T12:28:59.312209Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
    "                                                requires_grad=True, # <- can we update this value with gradient descent?\n",
    "                                                dtype=torch.float # <- PyTorch loves float32 by default\n",
    "        ))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(1, \n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float\n",
    "        ))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea39fdc3-ddf8-442e-b420-7d528bb7f6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:59.321346Z",
     "iopub.status.busy": "2022-09-27T12:28:59.320815Z",
     "iopub.status.idle": "2022-09-27T12:28:59.327362Z",
     "shell.execute_reply": "2022-09-27T12:28:59.326885Z",
     "shell.execute_reply.started": "2022-09-27T12:28:59.321311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c19b1e9c-ffd0-423b-8a86-a9b47896a854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:59.328579Z",
     "iopub.status.busy": "2022-09-27T12:28:59.328284Z",
     "iopub.status.idle": "2022-09-27T12:28:59.371141Z",
     "shell.execute_reply": "2022-09-27T12:28:59.370396Z",
     "shell.execute_reply.started": "2022-09-27T12:28:59.328559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23d83401-7c29-4f76-a8de-477a2bb0edba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:59.372511Z",
     "iopub.status.busy": "2022-09-27T12:28:59.372176Z",
     "iopub.status.idle": "2022-09-27T12:28:59.377225Z",
     "shell.execute_reply": "2022-09-27T12:28:59.376763Z",
     "shell.execute_reply.started": "2022-09-27T12:28:59.372489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251],\n",
       "        [0.4318],\n",
       "        [0.4386],\n",
       "        [0.4453],\n",
       "        [0.4520],\n",
       "        [0.4588]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "    \n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32817ffd-d9fb-4944-9af2-4c7919c67e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:28:59.378395Z",
     "iopub.status.busy": "2022-09-27T12:28:59.378097Z",
     "iopub.status.idle": "2022-09-27T12:28:59.699191Z",
     "shell.execute_reply": "2022-09-27T12:28:59.698687Z",
     "shell.execute_reply.started": "2022-09-27T12:28:59.378376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "883cdbe3-cde9-4818-a1fe-2784b2c8876e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:36:48.839849Z",
     "iopub.status.busy": "2022-09-27T12:36:48.839027Z",
     "iopub.status.idle": "2022-09-27T12:36:48.844633Z",
     "shell.execute_reply": "2022-09-27T12:36:48.843743Z",
     "shell.execute_reply.started": "2022-09-27T12:36:48.839809Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setup loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#Setup optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.0001) #lr = learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e4d0958-2273-4e7b-9ccf-ddd9d9a2ba2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:36:52.853017Z",
     "iopub.status.busy": "2022-09-27T12:36:52.851968Z",
     "iopub.status.idle": "2022-09-27T12:36:53.668973Z",
     "shell.execute_reply": "2022-09-27T12:36:53.666597Z",
     "shell.execute_reply.started": "2022-09-27T12:36:52.852984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss tensor(0.0089, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0088, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0087, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0086, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0085, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0084, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0082, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0081, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0080, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0079, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0078, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0077, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0076, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0074, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0073, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0072, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0071, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0070, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0069, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0067, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0066, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0065, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0064, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0063, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0062, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0061, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0059, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0058, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0057, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0056, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0055, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0054, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0053, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0051, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0050, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0049, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0048, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0047, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0046, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0044, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0043, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0042, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0041, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0040, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0039, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0038, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0036, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0035, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0034, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0033, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0032, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0031, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0029, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0028, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0027, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0026, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0025, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0024, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0023, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0021, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0020, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0019, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0018, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0017, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0016, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0015, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0013, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0012, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0012, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0011, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0010, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0010, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0010, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0009, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0009, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0009, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0009, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0008, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0007, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0006, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0005, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0004, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0003, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0002, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(0.0001, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(9.8264e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(9.4818e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(9.1407e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(8.7924e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(8.4553e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(8.1061e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.7669e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.4205e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.0774e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(6.7353e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(6.3877e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(6.0498e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(5.7004e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(5.3623e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(5.0149e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(4.6725e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(4.3298e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.9827e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.6446e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.2945e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(2.9566e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(2.6093e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(2.2679e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(1.9241e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(1.5783e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(1.2453e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(1.3161e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(3.8651e-05, grad_fn=<L1LossBackward0>)\n",
      "Loss tensor(7.6539e-05, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# an epoch is one loop through the data\n",
    "epochs = 1000\n",
    "\n",
    "#Track different values\n",
    "epoch_count = []\n",
    "loss_values = ()\n",
    "test_loss_values = []\n",
    "\n",
    "#0. loop through the data\n",
    "for epoch in range(epochs):\n",
    "    #Set the model to training mode\n",
    "    model_0.train() # train mode in pytorch sets all parameters that require gradients to require gradients\n",
    "\n",
    "    #1. forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "    \n",
    "    #2. Calculate the loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print(\"Loss\", loss)\n",
    "    \n",
    "    #3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #4. Perform backpropagation on loss with respect to parameters of the model\n",
    "    loss.backward()\n",
    "    \n",
    "    #5. Step the optimizer, perform gradient descent\n",
    "    optimizer.step()\n",
    "    \n",
    "    model_0.eval() # turns off gradient tracking\n",
    "    with torch.inference_mode(): # turns off gradient tracking\n",
    "        #1. do the forward pass\n",
    "        test_pred = model_0(X_test)\n",
    "        \n",
    "        #2. calculate the loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "if epoch % 10 == 0:\n",
    "    epoch_count.append(epoch)\n",
    "    loss_values.append(loss)\n",
    "    test_loss_values.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0328ecf6-4d4b-455b-bfe7-78b8654a6611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:37:04.472191Z",
     "iopub.status.busy": "2022-09-27T12:37:04.471868Z",
     "iopub.status.idle": "2022-09-27T12:37:04.479319Z",
     "shell.execute_reply": "2022-09-27T12:37:04.478483Z",
     "shell.execute_reply.started": "2022-09-27T12:37:04.472167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6db538a5-3562-4d90-b264-9122562548fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:36:58.102262Z",
     "iopub.status.busy": "2022-09-27T12:36:58.101942Z",
     "iopub.status.idle": "2022-09-27T12:36:58.378668Z",
     "shell.execute_reply": "2022-09-27T12:36:58.378034Z",
     "shell.execute_reply.started": "2022-09-27T12:36:58.102240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGbCAYAAADgEhWsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtbklEQVR4nO3deXxU9b3/8fcHhiWyiRBEEjYFBIyIEGmpC6hYlUVarQpYC7/2Snwott66UbVsaqnVyrUVLdgq7jt6uYhopaDoFSWAUCFgEVTECEF7XbAKIZ/fHxPTJCaZSc5smXk9H495TM453znnM5ygb77nzGfM3QUAAICGaZLsAgAAABozwhQAAEAAhCkAAIAACFMAAAABEKYAAAACCCXrwB07dvQePXok6/AAAABRW7NmzR53z65pW9LCVI8ePVRYWJiswwMAAETNzN6rbRuX+QAAAAIgTAEAAARAmAIAAAiAMAUAABAAYQoAACCAiJ/mM7N7JI2WtNvd82rYbpJulzRS0peSJrn72qCFffbZZ9q9e7f2798fdFfIEM2aNVOnTp3Utm3bZJcCAMgg0bRGWCDpDkn317L9TEm9yx/fkXRX+XODffbZZ9q1a5dycnKUlZWlcF4Daufu+te//qWdO3dKEoEKAJAwES/zufvLkj6pY8hYSfd72CpJB5vZYUGK2r17t3JycnTQQQcRpBAVM9NBBx2knJwc7d69O9nlAAAySCzumcqRtKPS8gfl6xps//79ysrKClQUMlNWVhaXhgEACZXQG9DNbLKZFZpZYUlJSaSxCaoK6YTfGwBAosUiTO2U1LXScm75um9x9/nunu/u+dnZNX69DQAAQKMSizC1SNJPLOy7kj519+IY7BcAACDlRQxTZvaIpNckHWlmH5jZz8zsYjO7uHzIEknbJG2VdLekS+JWbQaaNGmSRo8eXa/XDB8+XFOmTIlTRQAAoLKIrRHcfXyE7S7p0phV1EhFuldn4sSJWrBgQb33e/vttyv8Rxy9hQsXqlmzZvU+Vn3NmDFDM2fOlCQ1bdpUbdu2Vd++fTVmzBhddtllat26ddT7evfdd9WzZ0+tXr1a+fn58SoZAICYi6bPFKJQXPzvK5uLFy/WRRddVGVd9U8n7t+/P6rA065du3rXcsghh9T7NQ115JFHasWKFXJ3ffLJJ3rllVc0e/Zs3XPPPVq5cqU6d+6csFoAAEgGvk4mRjp37lzxOPjgg6us++qrr3TwwQfrkUce0SmnnKKsrCzNmzdPH3/8scaPH6/c3FxlZWXpqKOO0r333ltlv9Uv8w0fPlyXXHKJrr32WnXs2FGdOnXSlVdeqbKysipjKl/m69Gjh2688UYVFBSobdu2ys3N1S233FLlOG+//baGDRumli1b6sgjj9SSJUvUunXriLNpoVBInTt31mGHHaajjjpKBQUFeu211/TJJ5/ommuuqRi3dOlSnXjiiWrfvr0OOeQQnX766SoqKqrY3rNnT0nScccdJzPT8OHDJUmrV6/W97//fXXs2FFt27bVCSecoNdeey3yCQEAZISXRh+t0iaml0YfnbQaCFMJ9Ktf/UqXXHKJNm3apB/84Af66quvNGjQIC1evFgbN27UL37xCxUUFGjZsmV17uehhx5SKBTS//7v/+qOO+7Qf/3Xf+mxxx6r8zVz5szR0UcfrbVr1+qaa67R1VdfXRFKysrK9MMf/lChUEirVq3SggULNHPmTH399dcNep+HHXaYLrjgAj3zzDMVIW/v3r26/PLL9cYbb2jFihVq166dxowZo3379kmS3njjDUnh0FVcXKyFCxdKkj7//HNdeOGFWrlypd544w0NHDhQI0eO1Mcff9yg2gAA6eX4JW8p5OHnZEn7MHXppVIoFH5Otssuu0w/+tGP1LNnT+Xm5ionJ0dXXXWVBg4cqMMPP1yTJ0/W2WefrUceeaTO/fTv31+zZs1Snz59dN555+nkk0+OGMC+//3va8qUKerVq5cuu+wy9erVq+I1f/3rX7Vlyxbdf//9GjhwoIYOHao5c+aotLS0we+1f//++uyzz7Rnzx5J0jnnnKNzzjlHvXv31oABA3Tvvfdq+/btFSHqm1YZHTp0UOfOnSsuVZ5yyim68MIL1a9fP/Xt21d//OMf1bJlSz333HMNrg0AkD5eHZmnUgs/J0vah6l586QDB8LPyVb9xuoDBw7opptu0oABA9ShQwe1bt1aCxcu1Pvvv1/nfgYMGFBluUuXLhG/QqWu12zevFldunRRTs6/G9cfd9xxatKk4b8e39w0/82N+e+8844mTJigI444Qm3bttWhhx6qsrKyiO919+7dKigoUJ8+fdSuXTu1adNGu3fvjvg6AEBmGLb47wqVuYYt/nvSakj7G9ALCsJBqqAg2ZVIrVq1qrJ866236ve//71uv/12HX300WrdurWuvfbaiMGo+o3rZlblnqlYvSaITZs2qW3bturQoYMkafTo0crNzdW8efOUk5OjUCik/v37V1zmq83EiRO1a9cuzZkzRz169FCLFi106qmnRnwdAACJkvZhau7c8CMVvfLKKxozZowuvPBCSeHZnLfffrviBvZE6du3rz788EN9+OGH6tKliySpsLCwwWGruLhYDz/8sM4++2w1adJEH3/8sTZv3qw777xTJ598siRp7dq1VS4jNm/eXFJ4tq6yV155RX/4wx80atQoSdKuXbuqfEoSAIBkS/vLfKmsT58+WrZsmV555RVt3rxZU6ZM0fbt2xNex2mnnaYjjzxSEydO1Pr167Vq1Sr98pe/VCgUitg/q7S0VB999JGKi4u1ceNGzZ8/X0OHDtUhhxyi2bNnS5Lat2+vjh076u6779bWrVv10ksv6eKLL1Yo9O8s36lTJ2VlZen555/Xrl279Omnn0oK/xk9+OCD2rRpk1avXq1x48ZVBC8AAFIBYSqJrr/+eg0ZMkRnnnmmTjrpJLVq1UoXXHBBwuto0qSJnn76aX399dcaMmSIJk6cqOuuu05mppYtW9b52i1btuiwww5Tbm6uTjjhBN17772aPHmy1q5dW9FjqkmTJnrssce0YcMG5eXl6dJLL9UNN9ygFi1aVOwnFArpD3/4g/785z+rS5cuGjt2rCTpnnvu0RdffKHBgwdr3Lhx+ulPf6oePXrE7c8CAJB8qdDuoD6svt21YyU/P98LCwtr3FZUVKR+/foluCJUtn79eg0cOFCFhYUaPHhwssupF35/AKBxK21iCrlUalKoLDk5pTozW+PuNX5FBzNTkCQ9/fTTeuGFF7R9+3YtX75ckyZN0jHHHKNBgwYluzQAQIZJhXYH9ZH2N6AjOp9//rmuueYa7dixQ+3bt9fw4cM1Z86ciPdMAQAQa9+0ORiW5DqiRZiCJOknP/mJfvKTnyS7DAAAGh0u8wEAAARAmAIAAAiAMAUAABKisbU8iBZhCgAAJMTxS95SyMPP6YQwBQAAEqKxtTyIFp/mAwAACdHYWh5Ei5mpRqxHjx669dZbk10GAAAZjTAVI2ZW52PSpEkN3veMGTOUl/ftKdHVq1frkksuCVB1dCZNmlTxPpo1a6ZOnTrp5JNP1ty5c7V///567WvFihUyM+3ZsydO1QIAkFhc5ouR4uLiip8XL16siy66qMq6rKysmB8zOzs75vuszYgRI/TAAw/owIEDKikp0d/+9jdNnz5dDzzwgJYtW6ZWrVolrBYAAFIJM1Mx0rlz54rHwQcf/K11L7/8sgYPHqyWLVuqZ8+euu6667Rv376K1y9cuFADBgxQVlaWDjnkEA0bNky7du3SggULNHPmTG3cuLFidmjBggWSvn2Zz8w0f/58nXvuuWrVqpUOP/xwPfjgg1XqfP311zVo0CC1bNlSxx57rJYsWSIz04oVK+p8fy1atFDnzp2Vk5OjgQMH6pe//KVWrFihtWvX6ne/+13FuAcffFDHHXec2rRpo06dOuncc8/Vzp07JUnvvvuuTj75ZEnhIFh5xm7p0qU68cQT1b59ex1yyCE6/fTTVVRU1JBTAQBIsHRteRAtwlQCPP/887rgggs0ZcoUbdy4Uffcc4+efPJJXXvttZKkjz76SOPGjdPEiRNVVFSkl19+WRdeeKEk6fzzz9cVV1yhI488UsXFxSouLtb5559f67FmzZqlsWPHav369Tr//PP105/+VO+//74k6YsvvtDo0aPVt29frVmzRr/73e901VVXNfh95eXl6YwzztBTTz1VsW7fvn2aOXOm1q9fr8WLF2vPnj0aP368JKlr164VYzdu3Kji4mLdfvvtkqS9e/fq8ssv1xtvvKEVK1aoXbt2GjNmTJXACQBITena8iBq7p6Ux+DBg702mzZtqnVbfV2y+BJvOrOpX7L4kpjtM5InnnjCw3+0YSeeeKLPmjWrypinn37aW7Vq5WVlZb5mzRqX5O+++26N+5s+fbofddRR31rfvXt3v+WWWyqWJfnUqVMrlvfv3+9ZWVn+wAMPuLv7n/70J2/fvr1/+eWXFWMeeughl+TLly+v9f1MnDjRR40aVeO2a665xrOysmp9bVFRkUvyHTt2uLv78uXLXZKXlJTU+hp39y+++MKbNGniK1eurHNcTWL5+wMAiGzFqDzfb/IVo/KSXUrcSCr0WjJN2s9MzVszTwf8gOatmZe0GtasWaObbrpJrVu3rnhMmDBBe/fu1UcffaRjjjlGI0aMUF5ens455xzdddddKikpadCxBgwYUPFzKBRSdna2du/eLUnavHmz8vLyqty/9Z3vfCfQe3N3mVnF8tq1azV27Fh1795dbdq0UX5+viRVzI7V5p133tGECRN0xBFHqG3btjr00ENVVlYW8XUAgOQbtvjvCpV5ReuDTJP2YapgcIGaWlMVDC5IWg1lZWWaPn263nzzzYrHhg0b9I9//EPZ2dlq2rSpXnjhBb3wwgsaMGCA/vKXv6h3795av359vY/VrFmzKstmprKysli9lW/ZtGmTDj/8cEnhS3Wnn366DjroID3wwANavXq1li5dKkkRL9eNHj1aJSUlmjdvnl5//XWtW7dOoVCIy3wAgJSX9p/mmztqruaOmpvUGgYNGqTNmzerV69etY4xMw0dOlRDhw7VtGnTdNRRR+mxxx7TMccco+bNm+vAgQOB6+jbt6/uu+8+/etf/6qYnXrjjTcavL+33npLS5cu1fXXXy8pPPO1Z88e/eY3v1HPnj0lhW+sr6x58+aSVOX9fPzxx9q8ebPuvPPOihvU165dq9LS0gbXBgBAoqT9zFQqmDZtmh5++GFNmzZNb731ljZv3qwnn3xSV199tSRp1apVuvHGG7V69Wq9//77WrRokXbs2KH+/ftLCn9q77333tPatWu1Z88eff311w2qY8KECWratKkuuugibdq0SS+++KJ+85vfSFKVS3U1+frrr/XRRx/pww8/1Pr163Xbbbdp+PDhGjx4sK688kpJUrdu3dSiRQvdcccd2rZtm5599ln9+te/rrKf7t27y8z07LPPqqSkRF988YXat2+vjh076u6779bWrVv10ksv6eKLL1YolPZZHwCQBghTCXD66afr2Wef1fLlyzVkyBANGTJEv/3tb9WtWzdJUrt27fTqq69q9OjR6t27t6644gr9+te/1o9//GNJ0jnnnKORI0fq1FNPVXZ2th555JEG1dGmTRv9z//8jzZu3Khjjz1WV111lWbMmCFJatmyZZ2vffHFF3XYYYepW7duOvXUU7Vo0SLNmDFDL7/8ckWPqezsbN1333165pln1L9/f82cOVO33XZblf3k5ORo5syZuu6663TooYdqypQpatKkiR577DFt2LBBeXl5uvTSS3XDDTeoRYsWDXqfAIDgMr3dQX1Y+Ab1xMvPz/fCwsIatxUVFalfv34Jrigz/fd//7d++MMfavfu3erYsWOyy4kJfn8AILjSJqaQS6UmhcqSkxVSiZmtcff8mrYxM5Vh7rvvPq1cuVLvvvuuFi9erMsvv1xjxoxJmyAFAIiNV0fmqdTCz6gbN6VkmF27dmn69OkqLi5W586dNWrUKN18883JLgsAkGK+aXMwLMl1NAaEqQxz9dVXV9z4DgAAguMyHwAAQACEKQAAgAAIUwAAZBBaHsQeYQoAgAxy/JK3FPLwM2KDMAUAQAah5UHs8Wk+AAAyCC0PYo+ZqUboySefrPJdegsWLFDr1q0D7XPFihUyM+3ZsydoeQAAZBTCVAxNmjRJZiYzU7NmzXT44Yfryiuv1N69e+N63PPPP1/btm2LenyPHj106623Vln3ve99T8XFxerQoUOsywMAIK1FFabM7Awz22JmW81sag3bu5vZMjPbYGYrzCw39qU2DiNGjFBxcbG2bdumG2+8UXfeeaeuvPLKb40rLS1VrL4XMSsrS506dQq0j+bNm6tz585VZrwAAEBkEcOUmTWVNFfSmZL6SxpvZv2rDbtV0v3uPkDSLEmzY11oY9GiRQt17txZXbt21YQJE3TBBRfomWee0YwZM5SXl6cFCxboiCOOUIsWLbR37159+umnmjx5sjp16qQ2bdpo2LBhqv4F0Pfff7+6d++ugw46SKNHj9auXbuqbK/pMt+SJUv0ne98R1lZWerQoYPGjBmjr776SsOHD9d7772nq666qmIWTar5Mt/ChQt19NFHq0WLFuratatuuummKgGwR48euvHGG1VQUKC2bdsqNzdXt9xyS5U65s2bpz59+qhly5bq2LGjTj/9dJWWlsbkzxoA8G+0PEieaGamhkja6u7b3H2fpEclja02pr+kv5X/vLyG7RkrKytL+/fvlyRt375dDz/8sJ544gmtX79eLVq00KhRo7Rz504tXrxY69at00knnaRTTjlFxcXFkqTXX39dkyZN0uTJk/Xmm29qzJgxmjZtWp3HXLp0qc466yyddtppWrNmjZYvX65hw4aprKxMCxcuVG5urqZNm6bi4uKK41S3Zs0anXvuuTr77LP197//Xb/97W81e/Zs3XHHHVXGzZkzR0cffbTWrl2ra665RldffbVee+01SVJhYaEuvfRSTZ8+XVu2bNGyZct0xhlnBP0jBQDUgJYHSeTudT4k/UjSnystXyjpjmpjHpb0i/Kfz5bkkjrUsK/JkgolFXbr1s1rs2nTplq31dsll7g3bRp+jrOJEyf6qFGjKpZff/1179Chg5933nk+ffp0D4VC/tFHH1VsX7Zsmbdq1cq//PLLKvs55phj/Oabb3Z39/Hjx/uIESOqbP/Zz37m4VMXdu+993qrVq0qlr/3ve/5+eefX2ud3bt391tuuaXKuuXLl7skLykpcXf3CRMm+Mknn1xlzPTp0z0nJ6fKfsaNG1dlTK9evfyGG25wd/ennnrK27Zt65999lmttcRDTH9/AKCRWDEqz/ebfMWovGSXkpYkFXotWSlWN6BfKWmYma1T+NOWOyUdqCG4zXf3fHfPz87OjtGhI5g3TzpwIPycAEuXLlXr1q3VsmVLDR06VCeddJL++Mc/SpJyc3N16KGHVoxds2aNvvzyS2VnZ6t169YVj7feekvvvPOOJKmoqEhDhw6tcozqy9WtW7dOp556aqD3UVRUpOOPP77KuhNOOEE7d+7UZ599VrFuwIABVcZ06dJFu3fvliSddtpp6t69u3r27KkLLrhA9913nz7//PNAdQEAajZs8d8VKvOK1gdInGj6TO2U1LXScm75ugru/qHCM1Iys9aSznH3/4tRjcEUFISDVEFBQg530kknaf78+WrWrJm6dOmiZs2aVWxr1apVlbFlZWU69NBDtXLlym/tp23btnGvtaEq36Re+f19s62srEyS1KZNG61du1Yvv/yy/vrXv2r27Nm69tprtXr1anXp0iWhNQMAEC/RzEytltTbzHqaWXNJ4yQtqjzAzDqa2Tf7+pWke2JbZgBz50qlpeHnBDjooIPUq1cvde/e/VtBo7pBgwZp165datKkiXr16lXl8c2n8/r166dVq1ZVeV315eqOPfZYLVu2rNbtzZs314ED35o4rKJfv3569dVXq6x75ZVXlJubqzZt2tT52spCoZBOOeUUzZ49Wxs2bNDevXu1ePHiqF8PAECqixim3L1U0hRJz0sqkvS4u280s1lmdlb5sOGStpjZ25IOlXRTnOpNKyNGjNDxxx+vsWPH6rnnntP27dv12muvafr06RWzVT//+c/14osvavbs2frHP/6hu+++W08//XSd+73uuuv0xBNP6Prrr9emTZu0ceNGzZkzR19++aWk8KfwVq5cqZ07d9bapPOKK67QSy+9pBkzZujtt9/WQw89pN///ve6+uqro35/ixcv1u23365169bpvffe08MPP6zPP/9c/fr1i3ofAACkuqjumXL3Je7ex92PcPebytdNc/dF5T8/6e69y8f8h7t/Hc+i04WZacmSJTrllFN00UUX6cgjj9R5552nLVu2VFwG++53v6u//OUvuuuuuzRgwAAtXLhQM2bMqHO/I0eO1NNPP63nnntOxx57rIYNG6bly5erSZPw6Z41a5Z27NihI444QrXduzZo0CA98cQTeuqpp5SXl6epU6dq6tSpmjJlStTv7+CDD9YzzzyjESNGqG/fvrr11lv15z//WSeeeGLU+wCATEa7g8bBPEaNI+srPz/fq/dT+kZRURGzF2gwfn8ApIvSJqaQS6UmhcqS8/9rhJnZGnfPr2kbXycDAECKenVknkot/IzUFc2n+QAAQBJ80+ZgWJLrQN2YmQIAAAiAMAUAABBAyoapbxo/AvXB7w0AINFSMky1atVKO3fu1L59+5SsTxuicXF37du3Tzt37vxWp3kASDW0PEgvKdkaoaysTHv27NGnn36q0tLSBFeGxioUCqldu3bq2LFjRU8tAEhFtDxofOpqjZCSn+Zr0qSJOnXqVPGVKgAApJNXR+bp+CVv6dWReXxSLw2kZJgCACCd0fIgvXAtBAAAIADCFAAAQACEKQAAgAAIUwAAxAgtDzITYQoAgBg5fslbCnn4GZmDMAUAQIy8OjJPpRZ+RuagNQIAADFCy4PMxMwUAABAAIQpAACAAAhTAAAAARCmAACow6WXSqFQ+BmoCWEKAIA6zJsnHTgQfgZqQpgCAKAOBQVS06bhZ6Am5u5JOXB+fr4XFhYm5dgAAAD1YWZr3D2/pm3MTAEAAARAmAIAAAiAMAUAABAAYQoAkJFoeYBYIUwBADISLQ8QK4QpAEBGouUBYoXWCAAAABHQGgEAACBOCFMAAAABEKYAAAACIEwBANIG7Q6QDIQpAEDaoN0BkoEwBQBIG7Q7QDLQGgEAACACWiMAAADECWEKAAAgAMIUAABAAFGFKTM7w8y2mNlWM5taw/ZuZrbczNaZ2QYzGxn7UgEAmYqWB0hlEW9AN7Omkt6WdJqkDyStljTe3TdVGjNf0jp3v8vM+kta4u496tovN6ADAKIVCoVbHjRtKpWWJrsaZKKgN6APkbTV3be5+z5Jj0oaW22MS2pb/nM7SR82tFgAAKqj5QFSWSiKMTmSdlRa/kDSd6qNmSHpBTO7TFIrSSNq2pGZTZY0WZK6detW31oBABlq7tzwA0hFsboBfbykBe6eK2mkpAfM7Fv7dvf57p7v7vnZ2dkxOjQAAEDyRBOmdkrqWmk5t3xdZT+T9LgkuftrklpK6hiLAgEAAFJZNGFqtaTeZtbTzJpLGidpUbUx70s6VZLMrJ/CYaokloUCAACkoohhyt1LJU2R9LykIkmPu/tGM5tlZmeVD7tC0kVmtl7SI5ImebK+pwYA0GjQ8gDpgO/mAwAkDS0P0Fjw3XwAgJREywOkA2amAAAAImBmCgAAIE4IUwAAAAEQpgAAAAIgTAEAYop2B8g0hCkAQEzNmxdudzBvXrIrARKDMAUAiCnaHSDT0BoBAAAgAlojAAAAxAlhCgAAIADCFAAAQACEKQAAgAAIUwCAqNA/CqgZYQoAEBX6RwE1I0wBAKJC/yigZvSZAgAAiIA+UwAAAHFCmAIAAAiAMAUAABAAYQoAMhwtD4BgCFMAkOFoeQAEQ5gCgAxHywMgGFojAAAAREBrBAAAgDghTAEAAARAmAIAAAiAMAUAaYh2B0DiEKYAIA3R7gBIHMIUAKQh2h0AiUNrBAAAgAhojQAAABAnhCkAAIAACFMAAAABEKYAoBGh5QGQeghTANCI0PIASD2EKQBoRGh5AKQeWiMAAABEQGsEAACAOCFMAQAABECYAgAACIAwBQApgJYHQOMVVZgyszPMbIuZbTWzqTVsn2Nmb5Y/3jaz/4t5pQCQxmh5ADReEcOUmTWVNFfSmZL6SxpvZv0rj3H3/3T3ge4+UNIfJS2MQ60AkLZoeQA0XtHMTA2RtNXdt7n7PkmPShpbx/jxkh6JRXEAkCnmzpVKS8PPABqXaMJUjqQdlZY/KF/3LWbWXVJPSX+rZftkMys0s8KSkpL61goAAJByYn0D+jhJT7r7gZo2uvt8d8939/zs7OwYHxoAACDxoglTOyV1rbScW76uJuPEJT4AAJBBoglTqyX1NrOeZtZc4cC0qPogM+srqb2k12JbIgA0TrQ7ADJDxDDl7qWSpkh6XlKRpMfdfaOZzTKzsyoNHSfpUU/Wl/0BQIqh3QGQGULRDHL3JZKWVFs3rdryjNiVBQCNX0FBOEjR7gBIb5asiaT8/HwvLCxMyrEBAADqw8zWuHt+Tdv4OhkAAIAACFMAAAABEKYAAAACIEwBQD3R8gBAZYQpAKgnWh4AqIwwBQD1VFAgNW1KywMAYbRGAAAAiIDWCAAAAHFCmAIAAAiAMAUAABAAYQoAytHyAEBDEKYAoBwtDwA0BGEKAMrR8gBAQ9AaAQAAIAJaIwAAAMQJYQoAACAAwhQAAEAAhCkAaY12BwDijTAFIK3R7gBAvBGmAKQ12h0AiDdaIwAAAERAawQAAIA4IUwBAAAEQJgCAAAIgDAFoFGi5QGAVEGYAtAo0fIAQKogTAFolGh5ACBV0BoBAAAgAlojAAAAxAlhCgAAIADCFAAAQACEKQAphZYHABobwhSAlELLAwCNDWEKQEqh5QGAxobWCAAAABHQGgEAACBOCFMAAAABEKYAAAACIEwBiDvaHQBIZ4QpAHFHuwMA6SyqMGVmZ5jZFjPbamZTaxlznpltMrONZvZwbMsE0JjR7gBAOovYGsHMmkp6W9Jpkj6QtFrSeHffVGlMb0mPSzrF3f9pZp3cfXdd+6U1AgAAaCyCtkYYImmru29z932SHpU0ttqYiyTNdfd/SlKkIAUAAJAuoglTOZJ2VFr+oHxdZX0k9TGzV81slZmdUdOOzGyymRWaWWFJSUnDKgYAAEghsboBPSSpt6ThksZLutvMDq4+yN3nu3u+u+dnZ2fH6NAAAADJE02Y2impa6Xl3PJ1lX0gaZG773f37QrfY9U7NiUCSFW0PACA6MLUakm9zaynmTWXNE7SompjnlF4Vkpm1lHhy37bYlcmgFREywMAiCJMuXuppCmSnpdUJOlxd99oZrPM7KzyYc9L+tjMNklaLukqd/84XkUDSA20PACAKFojxAutEQAAQGMRtDUCAAAAakGYAgAACIAwBQAAEABhCkAVtDsAgPohTAGognYHAFA/hCkAVdDuAADqh9YIAAAAEdAaAQAAIE4IUwAAAAEQpgAAAAIgTAEZgpYHABAfhCkgQ9DyAADigzAFZAhaHgBAfNAaAQAAIAJaIwAAAMQJYQoAACAAwhQAAEAAhCmgkaPlAQAkF2EKaORoeQAAyUWYAho5Wh4AQHLRGgEAACACWiMAAADECWEKAAAgAMIUAABAAIQpIAXR7gAAGg/CFJCCaHcAAI0HYQpIQbQ7AIDGg9YIAAAAEdAaAQAAIE4IUwAAAAEQpgAAAAIgTAEAAARAmAISiP5RAJB+CFNAAtE/CgDSD2EKSCD6RwFA+qHPFAAAQAT0mQIAAIgTwhQAAEAAhCkAAIAACFNADNDyAAAyF2EKiAFaHgBA5iJMATFAywMAyFxRhSkzO8PMtpjZVjObWsP2SWZWYmZvlj/+I/alAqlr7lyptDT8DADILKFIA8ysqaS5kk6T9IGk1Wa2yN03VRv6mLtPiUONAAAAKSuamakhkra6+zZ33yfpUUlj41sWAABA4xBNmMqRtKPS8gfl66o7x8w2mNmTZta1ph2Z2WQzKzSzwpKSkgaUCwAAkFpidQP6/0jq4e4DJP1V0n01DXL3+e6e7+752dnZMTo0EB+0OwAARCOaMLVTUuWZptzydRXc/WN3/7p88c+SBsemPCB5aHcAAIhGNGFqtaTeZtbTzJpLGidpUeUBZnZYpcWzJBXFrkQgOWh3AACIRsRP87l7qZlNkfS8pKaS7nH3jWY2S1Khuy+S9HMzO0tSqaRPJE2KY81AQsydS6sDAEBk5u5JOXB+fr4XFhYm5dgAAAD1YWZr3D2/pm10QAcAAAiAMAUAABAAYQoZh5YHAIBYIkwh49DyAAAQS4QpZBxaHgAAYolP8wEAAETAp/kAAADihDAFAAAQAGEKAAAgAMIU0gYtDwAAyUCYQtqg5QEAIBkIU0gbtDwAACQDrREAAAAioDUCAABAnBCmAAAAAiBMAQAABECYQkqj3QEAINURppDSaHcAAEh1hCmkNNodAABSHa0RAAAAIqA1AgAAQJwQpgAAAAIgTAEAAARAmEJS0PIAAJAuCFNICloeAADSBWEKSUHLAwBAuqA1AgAAQAS0RgAAAIgTwhQAAEAAhCkAAIAACFOIKVoeAAAyDWEKMUXLAwBApiFMIaZoeQAAyDS0RgAAAIiA1ggAAABxQpgCAAAIgDAFAAAQAGEKEdHuAACA2hGmEBHtDgAAqB1hChHR7gAAgNrRGgEAACCCwK0RzOwMM9tiZlvNbGod484xMzezGg8GAACQbiKGKTNrKmmupDMl9Zc03sz61zCujaRfSHo91kUCAACkqmhmpoZI2uru29x9n6RHJY2tYdwNkm6W9FUM6wMAAEhp0YSpHEk7Ki1/UL6ugpkNktTV3Z+ta0dmNtnMCs2ssKSkpN7FIrZoeQAAQHCBP81nZk0k3Sbpikhj3X2+u+e7e352dnbQQyMgWh4AABBcNGFqp6SulZZzy9d9o42kPEkrzOxdSd+VtIib0FMfLQ8AAAguYmsEMwtJelvSqQqHqNWSJrj7xlrGr5B0pbvX2feA1ggAAKCxCNQawd1LJU2R9LykIkmPu/tGM5tlZmfFtlQAAIDGJRTNIHdfImlJtXXTahk7PHhZAAAAjQNfJwMAABAAYSoN0fIAAIDEIUylIVoeAACQOISpNETLAwAAEidia4R4oTUCAABoLAK1RgAAAEDtCFMAAAABEKYAAAACIEw1ErQ7AAAgNRGmGgnaHQAAkJoIU40E7Q4AAEhNtEYAAACIgNYIAAAAcUKYAgAACIAwBQAAEABhKsloeQAAQONGmEoyWh4AANC4EaaSjJYHAAA0brRGAAAAiIDWCAAAAHFCmAIAAAiAMAUAABAAYSoOaHcAAEDmIEzFAe0OAADIHISpOKDdAQAAmYPWCAAAABHQGgEAACBOCFMAAAABEKYAAAACIEzVAy0PAABAdYSpeqDlAQAAqI4wVQ+0PAAAANXRGgEAACACWiMAAADECWEKAAAgAMIUAABAAIQp0fIAAAA0HGFKtDwAAAANR5gSLQ8AAEDD0RoBAAAgAlojAAAAxElUYcrMzjCzLWa21cym1rD9YjP7u5m9aWavmFn/2JcKAACQeiKGKTNrKmmupDMl9Zc0voaw9LC7H+3uAyX9TtJtsS4UAAAgFUUzMzVE0lZ33+bu+yQ9Kmls5QHu/lmlxVaSknMjFgAAQIJFE6ZyJO2otPxB+boqzOxSM3tH4Zmpn8emvIajdxQAAEiEmN2A7u5z3f0ISddIur6mMWY22cwKzaywpKQkVoeuEb2jAABAIkQTpnZK6lppObd8XW0elfSDmja4+3x3z3f3/Ozs7KiLbAh6RwEAgESIJkytltTbzHqaWXNJ4yQtqjzAzHpXWhwl6R+xK7Fh5s6VSkvDzwAAAPESijTA3UvNbIqk5yU1lXSPu280s1mSCt19kaQpZjZC0n5J/5Q0MZ5FAwAApIqIYUqS3H2JpCXV1k2r9PMvYlwXAABAo0AHdAAAgAAIUwAAAAEQpgAAAAIgTAEAAARAmAIAAAiAMAUAABAAYQoAACAAwhQAAEAAhCkAAIAACFMAAAABEKYAAAACIEwBAAAEYO6enAOblUh6L86H6ShpT5yPgYbj/KQuzk1q4/ykNs5P6gpybrq7e3ZNG5IWphLBzArdPT/ZdaBmnJ/UxblJbZyf1Mb5SV3xOjdc5gMAAAiAMAUAABBAuoep+ckuAHXi/KQuzk1q4/ykNs5P6orLuUnre6YAAADiLd1npgAAAOKKMAUAABBAWoQpMzvDzLaY2VYzm1rD9hZm9lj59tfNrEcSysxYUZyfX5rZJjPbYGbLzKx7MurMRJHOTaVx55iZmxkf906gaM6PmZ1X/vdno5k9nOgaM1UU/13rZmbLzWxd+X/bRiajzkxkZveY2W4ze6uW7WZmfyg/dxvMbFDQYzb6MGVmTSXNlXSmpP6SxptZ/2rDfibpn+7eS9IcSTcntsrMFeX5WScp390HSHpS0u8SW2VmivLcyMzaSPqFpNcTW2Fmi+b8mFlvSb+SdLy7HyXp8kTXmYmi/LtzvaTH3f1YSeMk3ZnYKjPaAkln1LH9TEm9yx+TJd0V9ICNPkxJGiJpq7tvc/d9kh6VNLbamLGS7iv/+UlJp5qZJbDGTBbx/Lj7cnf/snxxlaTcBNeYqaL5uyNJNyj8D5CvElkcojo/F0ma6+7/lCR3353gGjNVNOfGJbUt/7mdpA8TWF9Gc/eXJX1Sx5Cxku73sFWSDjazw4IcMx3CVI6kHZWWPyhfV+MYdy+V9KmkDgmpDtGcn8p+Jum5uFaEb0Q8N+XT313d/dlEFgZJ0f3d6SOpj5m9amarzKyuf40jdqI5NzMk/djMPpC0RNJliSkNUajv/5ciCgUqB4ghM/uxpHxJw5JdCyQzayLpNkmTklwKahdS+FLFcIVndF82s6Pd/f+SWRQkSeMlLXD335vZUEkPmFmeu5cluzDEXjrMTO2U1LXScm75uhrHmFlI4SnXjxNSHaI5PzKzEZKuk3SWu3+doNoyXaRz00ZSnqQVZvaupO9KWsRN6AkTzd+dDyQtcvf97r5d0tsKhyvEVzTn5meSHpckd39NUkuFv2QXyRfV/5fqIx3C1GpJvc2sp5k1V/hGv0XVxiySNLH85x9J+pvTrTRRIp4fMztW0jyFgxT3fCROnefG3T91947u3sPdeyh8P9tZ7l6YnHIzTjT/bXtG4VkpmVlHhS/7bUtgjZkqmnPzvqRTJcnM+ikcpkoSWiVqs0jST8o/1fddSZ+6e3GQHTb6y3zuXmpmUyQ9L6mppHvcfaOZzZJU6O6LJP1F4SnWrQrflDYueRVnlijPzy2SWkt6ovxzAe+7+1lJKzpDRHlukCRRnp/nJX3fzDZJOiDpKndn1j3Oojw3V0i628z+U+Gb0Sfxj/jEMLNHFP5HRsfye9amS2omSe7+J4XvYRspaaukLyX9v8DH5NwCAAA0XDpc5gMAAEgawhQAAEAAhCkAAIAACFMAAAABEKYAAAACIEwBAAAEQJgCAAAI4P8DGhbocycRJQwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a93b719-51c9-4cd5-a5f1-e5df1d5cf382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:37:11.101897Z",
     "iopub.status.busy": "2022-09-27T12:37:11.101528Z",
     "iopub.status.idle": "2022-09-27T12:37:11.392562Z",
     "shell.execute_reply": "2022-09-27T12:37:11.391565Z",
     "shell.execute_reply.started": "2022-09-27T12:37:11.101872Z"
    }
   },
   "outputs": [],
   "source": [
    "#Savjng a model\n",
    "from pathlib import Path\n",
    "\n",
    "#1. Creare models directory\n",
    "MODELPATH = Path(\"models\")\n",
    "MODELPATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#2. create model save path\n",
    "MODELNAME = \"01-Wrong-inputs-right-output.pth\"\n",
    "MODELSAVEPATH = MODELPATH / MODELNAME\n",
    "\n",
    "#3. save state dict\n",
    "torch.save(model_0.state_dict(), MODELSAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ef863f3-a3fb-4a91-8448-70291e301a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:40:02.871547Z",
     "iopub.status.busy": "2022-09-27T12:40:02.871028Z",
     "iopub.status.idle": "2022-09-27T12:40:02.879570Z",
     "shell.execute_reply": "2022-09-27T12:40:02.878630Z",
     "shell.execute_reply.started": "2022-09-27T12:40:02.871518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODELSAVEPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b472013-66cf-44bb-9635-22e73f5a2ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T12:40:20.329689Z",
     "iopub.status.busy": "2022-09-27T12:40:20.329328Z",
     "iopub.status.idle": "2022-09-27T12:40:20.337347Z",
     "shell.execute_reply": "2022-09-27T12:40:20.336534Z",
     "shell.execute_reply.started": "2022-09-27T12:40:20.329625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.7000])), ('bias', tensor([0.3000]))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_0.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
